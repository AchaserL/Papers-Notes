# 摘要
1. 任务：序列转录。
2. 过去常用的方法：循环或卷积神经网络，都包括一个编码器和一个解码器。
3. 最优模型通过注意力机制将编码器和解码器连接。
4. 本文：提出新的网络结构，Transformer，它只依靠注意力机制，完全没有用之前的循环和卷积。

# 结论
1. Transformer，第一个仅使用注意力的序列转录模型，它把之前在编码器-解码器架构中常用的循环层替换成了多头自注意力。

# 相关工作
> 1. 如何使用卷积网络替换循环神经网络，以减少时序的计算 ByteNet，ConvS2S。
> 2. 使用卷积网络，对于比较长的序列难以建模；需要多层卷积层才能将隔得比较远的两个像素的信息融合起来。
> 3. 使用Transformer，一层就可以把整个序列全部看到。
> 4. 卷积可以做多个输出通道，一个输出通道表示卷积识别到了不一样的模式；所以提出了Multi-Head Attention

> 1. 自注意力机制

# 模型架构
1. 序列模型里，现在表现比较好的是编码器和解码器架构
2. <font color=red>**编码器**</font>：将一个符号表示的输入序列 $(x_1, ..., x_n)$ 映射成为一个连续表示 $\vec{z} = (z_i, ..., z_n)$的序列，假设输入是一个句子，则$x_t$为第$t$个词的符号表示，$z_t$是它的向量表示；
编码器就是把原始输入映射为机器可以理解的向量
3. <font color=red>**解码器**</font>：给定$\vec{z}$，解码器每次会生成序列$(y_1, ..., y_m)$的一个符号，每一次符号的生成，模型都是自回归的，即利用前一次生成的符号作为生成下一个符号的额外输入（这里，下一个是指前一个的下一个，也就是当前这个）
## 编码器
1. 编码器由6个独立层堆叠而成；每层都有两个子层。
2. 第一个子层叫`multi-head self-attention`
3. 第二个子层叫`position-wise fully connected feed-forward network`，就是一个MLP
4. 每个子层都是用一个残差连接，最后在使用`layer normalization`
5. 公式 $LayerNorm(x + Sublayer(x))$，其中$Sublayer(x)$是子层自身实现的。$x + Sublayer(x)$表示残差连接；然后再过一层$LayerNorm$
6. 残差要求输入和输出维度相同（否则需要投影做维度转换），固定$d_{model} = 512$
7. 超参就两个：层数 $N$ 和 维度$d_{model}$
8. LayerNorm: 针对变长问题
9. 考虑BatchNorm，针对二维数据，列为特征，行为batch，BatchNorm要做的是
    * 训练时针对一个minibatch，对某个特征（列）进行正则化（均值变为0，方差变为1），
    * 预测时，针对整个数据集，求所有数据特征的均值和方差，进行正则化
10. LayerNorm，针对二维数据，列为特征，行为batch, LayerNorm要做的是对每个样本（行），做正则化
11. 针对Transformer，输入一般为三维，$(batch, len\_of\_sequence, d_{model})$，LayerNorm就是横着切出一片$(1, len\_of\_sequence, d_{model})$样本，其中，$len\_of\_sequence$每个样本都不一样
    * 如果使用BatchNorm， 会破坏不同句子的语义独立性；BatchNorm严重依赖批次大小，批次越大，均值/方差的估计越准确；NLP常见的两个问题：
        * 变长序列：句子长度不一，padding（补零）会干扰批次统计（零值会拉低均值 / 方差，导致归一化失真）；
        * 长序列限制：Transformer 处理长文本时（比如 1024 个词），硬件显存有限，只能用小批次（比如 batch_size=8 甚至 2），此时 BatchNorm 的批次统计量会非常不稳定（样本少导致均值 / 方差波动大），训练容易震荡。
    * LayerNorm对每个样本，计算它自己的均值和方差，不需要存储全局的均值和方差；Transformer依赖“单样本内的特征关联”，LayerNorm是单样本归一化，不会破坏样本内部的语义关联。
    * LayerNorm 训练和推理的逻辑完全一致（都是单样本内计算统计量），无需额外维护移动平均，避免了 “统计偏移” 问题。